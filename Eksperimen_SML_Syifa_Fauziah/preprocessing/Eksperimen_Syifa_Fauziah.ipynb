{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksperimen Machine Learning: Wine Quality Prediction\n",
    "\n",
    "**Author:** Syifa Fauziah  \n",
    "**Course:** Membangun Sistem Machine Learning - Dicoding  \n",
    "**Dataset:** UCI Wine Quality Dataset  \n",
    "**Date:** December 2025\n",
    "\n",
    "---\n",
    "\n",
    "Notebook ini berisi tahapan lengkap eksperimen machine learning meliputi:\n",
    "\n",
    "1. Import Libraries dan Konfigurasi\n",
    "2. Data Loading dari UCI Repository\n",
    "3. Exploratory Data Analysis (EDA)\n",
    "4. Data Preprocessing dan Feature Engineering\n",
    "5. Data Splitting (Train/Test)\n",
    "6. Feature Scaling\n",
    "7. Export Data dan Artifacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Dataset Introduction\n",
    "\n",
    "### Sumber Dataset\n",
    "Dataset yang digunakan dalam proyek ini adalah **UCI Wine Quality Dataset** yang tersedia di:\n",
    "- **Repository:** UCI Machine Learning Repository\n",
    "- **URL:** https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
    "- **Referensi:** P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis (2009)\n",
    "\n",
    "### Deskripsi Dataset\n",
    "Dataset ini berisi hasil analisis physicochemical dari sampel wine dari Portugal utara:\n",
    "- **Red Wine:** 1,599 sampel\n",
    "- **White Wine:** 4,898 sampel  \n",
    "- **Total:** 6,497 sampel setelah digabungkan\n",
    "\n",
    "### Fitur Dataset (11 Input Variables)\n",
    "| No | Fitur | Deskripsi | Satuan |\n",
    "|----|-------|-----------|--------|\n",
    "| 1 | fixed acidity | Asam tartarat dalam wine | g/dm\u00b3 |\n",
    "| 2 | volatile acidity | Asam asetat dalam wine | g/dm\u00b3 |\n",
    "| 3 | citric acid | Asam sitrat untuk kesegaran | g/dm\u00b3 |\n",
    "| 4 | residual sugar | Gula tersisa setelah fermentasi | g/dm\u00b3 |\n",
    "| 5 | chlorides | Kandungan garam | g/dm\u00b3 |\n",
    "| 6 | free sulfur dioxide | SO2 bebas untuk antimikroba | mg/dm\u00b3 |\n",
    "| 7 | total sulfur dioxide | Total SO2 | mg/dm\u00b3 |\n",
    "| 8 | density | Kepadatan wine | g/cm\u00b3 |\n",
    "| 9 | pH | Tingkat keasaman | - |\n",
    "| 10 | sulphates | Aditif antimikroba | g/dm\u00b3 |\n",
    "| 11 | alcohol | Kadar alkohol | % vol |\n",
    "\n",
    "### Target Variable\n",
    "- **quality:** Skor kualitas wine berdasarkan penilaian sensori\n",
    "- **Skala:** 0 (sangat buruk) hingga 10 (sangat baik)\n",
    "- **Distribusi aktual:** Mayoritas skor antara 5-7\n",
    "\n",
    "### Tujuan Proyek\n",
    "Membangun model machine learning untuk memprediksi kualitas wine berdasarkan karakteristik physicochemical-nya."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Import Libraries dan Konfigurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import joblib\n",
    "import json\n",
    "import warnings\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 10\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "\n",
    "print('Libraries imported successfully')\n",
    "print(f'Pandas version: {pd.__version__}')\n",
    "print(f'NumPy version: {np.__version__}')\n",
    "print(f'Execution timestamp: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Loading\n",
    "\n",
    "Dataset diambil dari UCI Machine Learning Repository. Dataset terdiri dari dua jenis wine:\n",
    "- Red Wine (1599 samples)\n",
    "- White Wine (4898 samples)\n",
    "\n",
    "Kedua dataset digabungkan dengan menambahkan kolom `wine_type` sebagai identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_WINE_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
    "WHITE_WINE_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv'\n",
    "\n",
    "print('Fetching data from UCI Machine Learning Repository...')\n",
    "\n",
    "try:\n",
    "    df_red = pd.read_csv(RED_WINE_URL, sep=';')\n",
    "    df_white = pd.read_csv(WHITE_WINE_URL, sep=';')\n",
    "    print('Data fetched successfully from UCI repository')\n",
    "except Exception as e:\n",
    "    print(f'Error fetching data: {e}')\n",
    "    raise\n",
    "\n",
    "df_red['wine_type'] = 'red'\n",
    "df_white['wine_type'] = 'white'\n",
    "\n",
    "df = pd.concat([df_red, df_white], axis=0, ignore_index=True)\n",
    "\n",
    "print(f'\\nDataset Statistics:')\n",
    "print(f'  Red wine samples: {len(df_red):,}')\n",
    "print(f'  White wine samples: {len(df_white):,}')\n",
    "print(f'  Total samples: {len(df):,}')\n",
    "print(f'  Number of features: {len(df.columns) - 1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_raw_dir = '../winequality_raw'\n",
    "os.makedirs(output_raw_dir, exist_ok=True)\n",
    "\n",
    "df.to_csv(f'{output_raw_dir}/winequality_combined.csv', index=False)\n",
    "df_red.drop(columns=['wine_type']).to_csv(f'{output_raw_dir}/winequality_red.csv', index=False)\n",
    "df_white.drop(columns=['wine_type']).to_csv(f'{output_raw_dir}/winequality_white.csv', index=False)\n",
    "\n",
    "print(f'Raw data saved to {output_raw_dir}/')\n",
    "print('Files created:')\n",
    "for f in os.listdir(output_raw_dir):\n",
    "    size = os.path.getsize(f'{output_raw_dir}/{f}') / 1024\n",
    "    print(f'  - {f} ({size:.1f} KB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Shape:', df.shape)\n",
    "print('\\nColumn Names and Data Types:')\n",
    "print('-' * 50)\n",
    "for col in df.columns:\n",
    "    print(f'  {col}: {df[col].dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('First 10 rows of the dataset:')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset Info:')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Tahap EDA meliputi analisis statistik deskriptif, pengecekan missing values dan duplikat, analisis distribusi target dan fitur, serta analisis korelasi antar variabel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Descriptive Statistics for Numerical Features:')\n",
    "desc_stats = df.describe().T\n",
    "desc_stats['range'] = desc_stats['max'] - desc_stats['min']\n",
    "desc_stats['cv'] = (desc_stats['std'] / desc_stats['mean']) * 100\n",
    "desc_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Additional Statistics:')\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "additional_stats = pd.DataFrame({\n",
    "    'skewness': df[numeric_cols].skew(),\n",
    "    'kurtosis': df[numeric_cols].kurtosis(),\n",
    "    'median': df[numeric_cols].median(),\n",
    "    'mode': df[numeric_cols].mode().iloc[0],\n",
    "    'iqr': df[numeric_cols].quantile(0.75) - df[numeric_cols].quantile(0.25)\n",
    "})\n",
    "additional_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage (%)': missing_percentage\n",
    "})\n",
    "\n",
    "print('Missing Values Analysis:')\n",
    "print('-' * 50)\n",
    "if missing_values.sum() == 0:\n",
    "    print('No missing values found in the dataset')\n",
    "else:\n",
    "    print(missing_df[missing_df['Missing Count'] > 0])\n",
    "\n",
    "print(f'\\nTotal missing values: {missing_values.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Duplicate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duplicates = df.duplicated().sum()\n",
    "duplicate_percentage = (total_duplicates / len(df)) * 100\n",
    "\n",
    "print('Duplicate Analysis:')\n",
    "print('-' * 50)\n",
    "print(f'Total duplicate rows: {total_duplicates:,}')\n",
    "print(f'Percentage of duplicates: {duplicate_percentage:.2f}%')\n",
    "\n",
    "if total_duplicates > 0:\n",
    "    print('\\nSample of duplicate rows:')\n",
    "    display(df[df.duplicated(keep='first')].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Target Variable Analysis (Quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quality Score Distribution:')\n",
    "quality_dist = df['quality'].value_counts().sort_index()\n",
    "quality_pct = (quality_dist / len(df) * 100).round(2)\n",
    "\n",
    "quality_analysis = pd.DataFrame({\n",
    "    'Count': quality_dist,\n",
    "    'Percentage (%)': quality_pct\n",
    "})\n",
    "print(quality_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'winequality_preprocessing'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "quality_counts = df['quality'].value_counts().sort_index()\n",
    "colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, len(quality_counts)))\n",
    "bars = axes[0].bar(quality_counts.index.astype(str), quality_counts.values, color=colors, edgecolor='black', linewidth=1.2)\n",
    "axes[0].set_xlabel('Quality Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Wine Quality Scores')\n",
    "for bar, count in zip(bars, quality_counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 30, \n",
    "                 str(count), ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "wine_type_counts = df['wine_type'].value_counts()\n",
    "wedges, texts, autotexts = axes[1].pie(\n",
    "    wine_type_counts.values, \n",
    "    labels=wine_type_counts.index.str.title(), \n",
    "    autopct='%1.1f%%',\n",
    "    colors=['#8B0000', '#DAA520'],\n",
    "    startangle=90,\n",
    "    explode=(0.02, 0.02),\n",
    "    shadow=True,\n",
    "    textprops={'fontsize': 11}\n",
    ")\n",
    "axes[1].set_title('Distribution of Wine Types')\n",
    "\n",
    "quality_by_type = df.groupby(['wine_type', 'quality']).size().unstack(fill_value=0)\n",
    "quality_by_type.T.plot(kind='bar', ax=axes[2], color=['#8B0000', '#DAA520'], edgecolor='black', width=0.7)\n",
    "axes[2].set_xlabel('Quality Score')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].set_title('Quality Distribution by Wine Type')\n",
    "axes[2].legend(title='Wine Type', loc='upper right')\n",
    "axes[2].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/01_quality_distribution.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/01_quality_distribution.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [col for col in numeric_cols if col != 'quality']\n",
    "\n",
    "n_features = len(feature_cols)\n",
    "n_cols = 4\n",
    "n_rows = int(np.ceil(n_features / n_cols))\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    ax.hist(df[col], bins=40, color='steelblue', edgecolor='white', alpha=0.7, density=True)\n",
    "    \n",
    "    mean_val = df[col].mean()\n",
    "    median_val = df[col].median()\n",
    "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.2f}')\n",
    "    ax.axvline(median_val, color='green', linestyle='-.', linewidth=2, label=f'Median: {median_val:.2f}')\n",
    "    \n",
    "    ax.set_title(f'{col}', fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=8, loc='upper right')\n",
    "\n",
    "for idx in range(len(feature_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Feature Distributions with Mean and Median', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/02_feature_distributions.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/02_feature_distributions.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_df.corr()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "            center=0, linewidths=0.5, square=True, cbar_kws={'shrink': 0.8},\n",
    "            ax=axes[0], annot_kws={'size': 8})\n",
    "axes[0].set_title('Feature Correlation Matrix (Lower Triangle)', fontsize=12, fontweight='bold')\n",
    "\n",
    "quality_corr = correlation_matrix['quality'].drop('quality').sort_values(key=abs, ascending=True)\n",
    "colors = ['#d73027' if x < 0 else '#1a9850' for x in quality_corr.values]\n",
    "bars = axes[1].barh(quality_corr.index, quality_corr.values, color=colors, edgecolor='black', linewidth=0.5)\n",
    "axes[1].axvline(x=0, color='black', linewidth=1)\n",
    "axes[1].set_xlabel('Correlation Coefficient')\n",
    "axes[1].set_title('Feature Correlations with Quality (Target)', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlim(-0.6, 0.6)\n",
    "\n",
    "for bar, val in zip(bars, quality_corr.values):\n",
    "    x_pos = val + 0.02 if val >= 0 else val - 0.02\n",
    "    ha = 'left' if val >= 0 else 'right'\n",
    "    axes[1].text(x_pos, bar.get_y() + bar.get_height()/2, f'{val:.3f}', \n",
    "                 va='center', ha=ha, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/03_correlation_analysis.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/03_correlation_analysis.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Feature Correlations with Quality (sorted by absolute value):')\n",
    "print('-' * 50)\n",
    "quality_correlations = correlation_matrix['quality'].drop('quality').sort_values(key=abs, ascending=False)\n",
    "\n",
    "for feature, corr in quality_correlations.items():\n",
    "    strength = 'Strong' if abs(corr) > 0.3 else 'Moderate' if abs(corr) > 0.15 else 'Weak'\n",
    "    direction = 'Positive' if corr > 0 else 'Negative'\n",
    "    print(f'  {feature}: {corr:.4f} ({strength} {direction})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Outlier Detection with Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "outlier_counts = {}\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
    "    outlier_counts[col] = len(outliers)\n",
    "    \n",
    "    bp = ax.boxplot(df[col], vert=True, patch_artist=True,\n",
    "                    boxprops=dict(facecolor='lightblue', color='navy'),\n",
    "                    medianprops=dict(color='red', linewidth=2),\n",
    "                    flierprops=dict(marker='o', markerfacecolor='red', markersize=4, alpha=0.5))\n",
    "    \n",
    "    ax.set_title(f'{col}\\n(Outliers: {len(outliers)})', fontsize=10, fontweight='bold')\n",
    "    ax.set_xticklabels([col])\n",
    "\n",
    "for idx in range(len(feature_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Boxplots for Outlier Detection', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/04_boxplots_outliers.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/04_boxplots_outliers.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Outlier Summary (using IQR method):')\n",
    "print('-' * 50)\n",
    "outlier_df = pd.DataFrame({\n",
    "    'Feature': list(outlier_counts.keys()),\n",
    "    'Outlier Count': list(outlier_counts.values()),\n",
    "    'Percentage (%)': [count/len(df)*100 for count in outlier_counts.values()]\n",
    "}).sort_values('Outlier Count', ascending=False)\n",
    "\n",
    "print(outlier_df.to_string(index=False))\n",
    "print(f'\\nTotal outlier instances: {sum(outlier_counts.values())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 Feature Comparison by Wine Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, 4*n_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    red_data = df[df['wine_type'] == 'red'][col]\n",
    "    white_data = df[df['wine_type'] == 'white'][col]\n",
    "    \n",
    "    ax.hist(red_data, bins=30, alpha=0.6, color='#8B0000', label='Red', density=True)\n",
    "    ax.hist(white_data, bins=30, alpha=0.6, color='#DAA520', label='White', density=True)\n",
    "    \n",
    "    ax.set_title(f'{col}', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.set_ylabel('Density')\n",
    "\n",
    "for idx in range(len(feature_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.suptitle('Feature Distributions by Wine Type', fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/05_features_by_wine_type.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/05_features_by_wine_type.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean Feature Values by Wine Type:')\n",
    "print('-' * 60)\n",
    "comparison = df.groupby('wine_type')[feature_cols].mean().T\n",
    "comparison['Difference'] = comparison['red'] - comparison['white']\n",
    "comparison['% Difference'] = (comparison['Difference'] / comparison['white'] * 100).round(2)\n",
    "comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 Pairplot for Key Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_features = ['alcohol', 'volatile acidity', 'sulphates', 'citric acid', 'quality']\n",
    "\n",
    "g = sns.pairplot(df[key_features + ['wine_type']], hue='wine_type', \n",
    "                 palette={'red': '#8B0000', 'white': '#DAA520'},\n",
    "                 diag_kind='kde', plot_kws={'alpha': 0.5, 's': 20},\n",
    "                 height=2.5)\n",
    "g.fig.suptitle('Pairplot of Key Features (Colored by Wine Type)', y=1.02, fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.savefig(f'{output_dir}/06_pairplot_key_features.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/06_pairplot_key_features.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Data Preprocessing\n",
    "\n",
    "Tahap preprocessing meliputi:\n",
    "1. Penghapusan data duplikat\n",
    "2. Feature Engineering (pembuatan fitur baru)\n",
    "3. Encoding variabel kategorikal\n",
    "4. Penanganan outlier menggunakan IQR capping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_rows = len(df)\n",
    "df_clean = df.drop_duplicates().reset_index(drop=True)\n",
    "removed_duplicates = initial_rows - len(df_clean)\n",
    "\n",
    "print('Duplicate Removal Results:')\n",
    "print('-' * 50)\n",
    "print(f'  Initial rows: {initial_rows:,}')\n",
    "print(f'  Duplicates removed: {removed_duplicates:,}')\n",
    "print(f'  Remaining rows: {len(df_clean):,}')\n",
    "print(f'  Reduction: {(removed_duplicates/initial_rows)*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating new features...')\n",
    "\n",
    "def create_quality_category(quality):\n",
    "    if quality <= 4:\n",
    "        return 'low'\n",
    "    elif quality <= 6:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "df_clean['quality_category'] = df_clean['quality'].apply(create_quality_category)\n",
    "\n",
    "df_clean['total_acidity'] = df_clean['fixed acidity'] + df_clean['volatile acidity']\n",
    "\n",
    "df_clean['bound_sulfur_dioxide'] = df_clean['total sulfur dioxide'] - df_clean['free sulfur dioxide']\n",
    "\n",
    "df_clean['sugar_to_alcohol'] = df_clean['residual sugar'] / (df_clean['alcohol'] + 0.001)\n",
    "\n",
    "df_clean['density_alcohol_ratio'] = df_clean['density'] / (df_clean['alcohol'] + 0.001)\n",
    "\n",
    "df_clean['free_sulfur_ratio'] = df_clean['free sulfur dioxide'] / (df_clean['total sulfur dioxide'] + 0.001)\n",
    "\n",
    "df_clean['acidity_to_pH'] = df_clean['total_acidity'] / (df_clean['pH'] + 0.001)\n",
    "\n",
    "print('\\nNew Features Created:')\n",
    "print('-' * 60)\n",
    "new_features = [\n",
    "    ('quality_category', 'Categorical version of quality (low/medium/high)'),\n",
    "    ('total_acidity', 'Sum of fixed and volatile acidity'),\n",
    "    ('bound_sulfur_dioxide', 'Total minus free sulfur dioxide'),\n",
    "    ('sugar_to_alcohol', 'Ratio of residual sugar to alcohol'),\n",
    "    ('density_alcohol_ratio', 'Ratio of density to alcohol'),\n",
    "    ('free_sulfur_ratio', 'Ratio of free to total sulfur dioxide'),\n",
    "    ('acidity_to_pH', 'Ratio of total acidity to pH')\n",
    "]\n",
    "\n",
    "for feature, description in new_features:\n",
    "    print(f'  {feature}: {description}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quality Category Distribution:')\n",
    "quality_cat_dist = df_clean['quality_category'].value_counts()\n",
    "print(quality_cat_dist)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "colors = {'low': '#d73027', 'medium': '#fee08b', 'high': '#1a9850'}\n",
    "bars = ax.bar(quality_cat_dist.index, quality_cat_dist.values, \n",
    "              color=[colors[cat] for cat in quality_cat_dist.index], edgecolor='black')\n",
    "ax.set_xlabel('Quality Category')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Quality Categories')\n",
    "\n",
    "for bar, count in zip(bars, quality_cat_dist.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50, \n",
    "            f'{count}\\n({count/len(df_clean)*100:.1f}%)', ha='center', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/07_quality_categories.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/07_quality_categories.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Updated Dataset Shape:', df_clean.shape)\n",
    "print('\\nUpdated Columns:')\n",
    "print(df_clean.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_wine_type = LabelEncoder()\n",
    "df_clean['wine_type_encoded'] = le_wine_type.fit_transform(df_clean['wine_type'])\n",
    "\n",
    "le_quality_cat = LabelEncoder()\n",
    "df_clean['quality_category_encoded'] = le_quality_cat.fit_transform(df_clean['quality_category'])\n",
    "\n",
    "print('Encoding Results:')\n",
    "print('-' * 50)\n",
    "print('wine_type encoding:')\n",
    "for cls, code in zip(le_wine_type.classes_, range(len(le_wine_type.classes_))):\n",
    "    print(f'  {cls} -> {code}')\n",
    "\n",
    "print('\\nquality_category encoding:')\n",
    "for cls, code in zip(le_quality_cat.classes_, range(len(le_quality_cat.classes_))):\n",
    "    print(f'  {cls} -> {code}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Handle Outliers using IQR Capping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_outliers_iqr(series, multiplier=1.5):\n",
    "    \"\"\"\n",
    "    Cap outliers using IQR method.\n",
    "    Values below Q1 - multiplier*IQR are set to lower bound.\n",
    "    Values above Q3 + multiplier*IQR are set to upper bound.\n",
    "    \"\"\"\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - multiplier * IQR\n",
    "    upper_bound = Q3 + multiplier * IQR\n",
    "    \n",
    "    n_lower = (series < lower_bound).sum()\n",
    "    n_upper = (series > upper_bound).sum()\n",
    "    \n",
    "    return series.clip(lower=lower_bound, upper=upper_bound), n_lower, n_upper\n",
    "\n",
    "outlier_features = [\n",
    "    'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "    'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "    'sulphates', 'total_acidity', 'bound_sulfur_dioxide', 'sugar_to_alcohol',\n",
    "    'density_alcohol_ratio', 'free_sulfur_ratio', 'acidity_to_pH'\n",
    "]\n",
    "\n",
    "capping_results = []\n",
    "\n",
    "print('Outlier Capping Results:')\n",
    "print('-' * 60)\n",
    "\n",
    "for col in outlier_features:\n",
    "    if col in df_clean.columns:\n",
    "        df_clean[col], n_lower, n_upper = cap_outliers_iqr(df_clean[col])\n",
    "        total_capped = n_lower + n_upper\n",
    "        if total_capped > 0:\n",
    "            print(f'  {col}: {total_capped} values capped (lower: {n_lower}, upper: {n_upper})')\n",
    "            capping_results.append({'feature': col, 'lower_capped': n_lower, 'upper_capped': n_upper})\n",
    "\n",
    "print(f'\\nTotal features processed: {len(outlier_features)}')\n",
    "print(f'Features with outliers capped: {len(capping_results)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Data Splitting\n",
    "\n",
    "Dataset dibagi menjadi training set (80%) dan test set (20%) dengan stratified sampling berdasarkan target variable (quality)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "    'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "    'pH', 'sulphates', 'alcohol', 'wine_type_encoded', 'total_acidity',\n",
    "    'bound_sulfur_dioxide', 'sugar_to_alcohol', 'density_alcohol_ratio',\n",
    "    'free_sulfur_ratio', 'acidity_to_pH'\n",
    "]\n",
    "\n",
    "X = df_clean[feature_columns].copy()\n",
    "y_regression = df_clean['quality'].copy()\n",
    "y_classification = df_clean['quality_category_encoded'].copy()\n",
    "\n",
    "print('Feature and Target Shapes:')\n",
    "print(f'  X (features): {X.shape}')\n",
    "print(f'  y_regression (quality score): {y_regression.shape}')\n",
    "print(f'  y_classification (quality category): {y_classification.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_regression, \n",
    "    test_size=TEST_SIZE, \n",
    "    random_state=RANDOM_STATE, \n",
    "    stratify=y_regression\n",
    ")\n",
    "\n",
    "_, _, y_train_cls, y_test_cls = train_test_split(\n",
    "    X, y_classification,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=y_classification\n",
    ")\n",
    "\n",
    "print('Train-Test Split Results:')\n",
    "print('-' * 50)\n",
    "print(f'  Training set: {X_train.shape[0]:,} samples ({(1-TEST_SIZE)*100:.0f}%)')\n",
    "print(f'  Test set: {X_test.shape[0]:,} samples ({TEST_SIZE*100:.0f}%)')\n",
    "print(f'  Number of features: {X_train.shape[1]}')\n",
    "print(f'  Random state: {RANDOM_STATE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "train_counts = y_train.value_counts().sort_index()\n",
    "colors_train = plt.cm.Blues(np.linspace(0.4, 0.9, len(train_counts)))\n",
    "bars1 = axes[0].bar(train_counts.index.astype(str), train_counts.values, color=colors_train, edgecolor='black')\n",
    "axes[0].set_xlabel('Quality Score')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title(f'Training Set Distribution (n={len(y_train):,})')\n",
    "for bar, count in zip(bars1, train_counts.values):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 10, \n",
    "                 str(count), ha='center', fontsize=9)\n",
    "\n",
    "test_counts = y_test.value_counts().sort_index()\n",
    "colors_test = plt.cm.Oranges(np.linspace(0.4, 0.9, len(test_counts)))\n",
    "bars2 = axes[1].bar(test_counts.index.astype(str), test_counts.values, color=colors_test, edgecolor='black')\n",
    "axes[1].set_xlabel('Quality Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title(f'Test Set Distribution (n={len(y_test):,})')\n",
    "for bar, count in zip(bars2, test_counts.values):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5, \n",
    "                 str(count), ha='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/08_train_test_distribution.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/08_train_test_distribution.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Stratification Verification:')\n",
    "print('-' * 50)\n",
    "\n",
    "train_dist = y_train.value_counts(normalize=True).sort_index() * 100\n",
    "test_dist = y_test.value_counts(normalize=True).sort_index() * 100\n",
    "original_dist = y_regression.value_counts(normalize=True).sort_index() * 100\n",
    "\n",
    "verification_df = pd.DataFrame({\n",
    "    'Original (%)': original_dist,\n",
    "    'Train (%)': train_dist,\n",
    "    'Test (%)': test_dist\n",
    "}).round(2)\n",
    "\n",
    "print(verification_df)\n",
    "print('\\nStratification preserved: Distribution is consistent across splits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Feature Scaling\n",
    "\n",
    "Feature scaling dilakukan menggunakan StandardScaler untuk menormalkan distribusi fitur sehingga memiliki mean=0 dan standard deviation=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)\n",
    "\n",
    "print('Feature Scaling Applied (StandardScaler)')\n",
    "print('-' * 50)\n",
    "print('Training set transformation: fit_transform()')\n",
    "print('Test set transformation: transform()')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scaled Training Data Statistics:')\n",
    "scaled_stats = X_train_scaled.describe().T[['mean', 'std', 'min', 'max']]\n",
    "scaled_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Scaler Parameters (Mean and Scale for each feature):')\n",
    "print('-' * 60)\n",
    "scaler_params = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Mean': scaler.mean_,\n",
    "    'Scale (Std)': scaler.scale_\n",
    "})\n",
    "scaler_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "sample_features = ['alcohol', 'volatile acidity', 'sulphates', 'citric acid']\n",
    "\n",
    "for feature in sample_features:\n",
    "    axes[0].hist(X_train[feature], bins=30, alpha=0.5, label=feature)\n",
    "axes[0].set_xlabel('Value')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Before Scaling (Original)')\n",
    "axes[0].legend()\n",
    "\n",
    "for feature in sample_features:\n",
    "    axes[1].hist(X_train_scaled[feature], bins=30, alpha=0.5, label=feature)\n",
    "axes[1].set_xlabel('Standardized Value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('After Scaling (StandardScaler)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{output_dir}/09_scaling_comparison.png', dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "print(f'Figure saved: {output_dir}/09_scaling_comparison.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Save Preprocessed Data dan Artifacts\n",
    "\n",
    "Menyimpan data hasil preprocessing dan artifacts (scaler, encoder, feature list) untuk digunakan dalam tahap modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Saving preprocessed data and artifacts...')\n",
    "print('-' * 50)\n",
    "\n",
    "X_train_scaled.to_csv(f'{output_dir}/X_train.csv', index=False)\n",
    "X_test_scaled.to_csv(f'{output_dir}/X_test.csv', index=False)\n",
    "print('Saved: X_train.csv, X_test.csv')\n",
    "\n",
    "y_train.to_csv(f'{output_dir}/y_train.csv', index=False, header=['quality'])\n",
    "y_test.to_csv(f'{output_dir}/y_test.csv', index=False, header=['quality'])\n",
    "print('Saved: y_train.csv, y_test.csv (regression targets)')\n",
    "\n",
    "y_train_cls.to_csv(f'{output_dir}/y_train_cls.csv', index=False, header=['quality_category'])\n",
    "y_test_cls.to_csv(f'{output_dir}/y_test_cls.csv', index=False, header=['quality_category'])\n",
    "print('Saved: y_train_cls.csv, y_test_cls.csv (classification targets)')\n",
    "\n",
    "df_clean.to_csv(f'{output_dir}/winequality_preprocessed_full.csv', index=False)\n",
    "print('Saved: winequality_preprocessed_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(scaler, f'{output_dir}/scaler.pkl')\n",
    "print('Saved: scaler.pkl')\n",
    "\n",
    "joblib.dump(le_wine_type, f'{output_dir}/label_encoder_wine_type.pkl')\n",
    "print('Saved: label_encoder_wine_type.pkl')\n",
    "\n",
    "joblib.dump(le_quality_cat, f'{output_dir}/label_encoder_quality_category.pkl')\n",
    "print('Saved: label_encoder_quality_category.pkl')\n",
    "\n",
    "joblib.dump(feature_columns, f'{output_dir}/feature_columns.pkl')\n",
    "print('Saved: feature_columns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_summary = {\n",
    "    'metadata': {\n",
    "        'author': 'Syifa Fauziah',\n",
    "        'course': 'Membangun Sistem Machine Learning - Dicoding',\n",
    "        'dataset': 'UCI Wine Quality',\n",
    "        'created_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'python_version': '3.9+'\n",
    "    },\n",
    "    'data_statistics': {\n",
    "        'original_samples': int(len(df)),\n",
    "        'red_wine_samples': int(len(df_red)),\n",
    "        'white_wine_samples': int(len(df_white)),\n",
    "        'duplicates_removed': int(removed_duplicates),\n",
    "        'samples_after_cleaning': int(len(df_clean))\n",
    "    },\n",
    "    'split_info': {\n",
    "        'train_samples': int(len(X_train)),\n",
    "        'test_samples': int(len(X_test)),\n",
    "        'train_ratio': float(1 - TEST_SIZE),\n",
    "        'test_ratio': float(TEST_SIZE),\n",
    "        'random_state': RANDOM_STATE,\n",
    "        'stratified': True\n",
    "    },\n",
    "    'feature_info': {\n",
    "        'n_features': len(feature_columns),\n",
    "        'original_features': 11,\n",
    "        'engineered_features': len(feature_columns) - 12,\n",
    "        'feature_names': feature_columns\n",
    "    },\n",
    "    'target_info': {\n",
    "        'regression_target': 'quality',\n",
    "        'classification_target': 'quality_category',\n",
    "        'quality_min': int(y_regression.min()),\n",
    "        'quality_max': int(y_regression.max()),\n",
    "        'quality_mean': float(y_regression.mean()),\n",
    "        'quality_std': float(y_regression.std())\n",
    "    },\n",
    "    'preprocessing_steps': [\n",
    "        'Load data from UCI repository',\n",
    "        'Combine red and white wine datasets',\n",
    "        'Remove duplicate rows',\n",
    "        'Feature engineering (7 new features)',\n",
    "        'Encode categorical variables',\n",
    "        'Cap outliers using IQR method',\n",
    "        'Train-test split (80/20, stratified)',\n",
    "        'StandardScaler normalization'\n",
    "    ],\n",
    "    'output_files': {\n",
    "        'training_features': 'X_train.csv',\n",
    "        'test_features': 'X_test.csv',\n",
    "        'training_target_regression': 'y_train.csv',\n",
    "        'test_target_regression': 'y_test.csv',\n",
    "        'training_target_classification': 'y_train_cls.csv',\n",
    "        'test_target_classification': 'y_test_cls.csv',\n",
    "        'full_preprocessed': 'winequality_preprocessed_full.csv',\n",
    "        'scaler': 'scaler.pkl',\n",
    "        'wine_type_encoder': 'label_encoder_wine_type.pkl',\n",
    "        'quality_category_encoder': 'label_encoder_quality_category.pkl',\n",
    "        'feature_list': 'feature_columns.pkl'\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(f'{output_dir}/preprocessing_summary.json', 'w') as f:\n",
    "    json.dump(preprocessing_summary, f, indent=2)\n",
    "\n",
    "print('\\nSaved: preprocessing_summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nOutput Directory Contents:')\n",
    "print('-' * 50)\n",
    "total_size = 0\n",
    "for f in sorted(os.listdir(output_dir)):\n",
    "    filepath = f'{output_dir}/{f}'\n",
    "    size = os.path.getsize(filepath)\n",
    "    total_size += size\n",
    "    print(f'  {f}: {size/1024:.1f} KB')\n",
    "\n",
    "print(f'\\nTotal size: {total_size/1024:.1f} KB ({total_size/1024/1024:.2f} MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Summary dan Kesimpulan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print('PREPROCESSING PIPELINE SUMMARY')\n",
    "print('=' * 70)\n",
    "\n",
    "print('\\n1. DATA LOADING')\n",
    "print(f'   - Source: UCI Machine Learning Repository')\n",
    "print(f'   - Red wine samples: {len(df_red):,}')\n",
    "print(f'   - White wine samples: {len(df_white):,}')\n",
    "print(f'   - Total samples: {len(df):,}')\n",
    "\n",
    "print('\\n2. DATA CLEANING')\n",
    "print(f'   - Duplicates removed: {removed_duplicates:,}')\n",
    "print(f'   - Final samples: {len(df_clean):,}')\n",
    "\n",
    "print('\\n3. FEATURE ENGINEERING')\n",
    "print(f'   - Original features: 11')\n",
    "print(f'   - New features created: {len(feature_columns) - 12}')\n",
    "print(f'   - Total features: {len(feature_columns)}')\n",
    "\n",
    "print('\\n4. DATA SPLITTING')\n",
    "print(f'   - Training set: {len(X_train):,} samples ({(1-TEST_SIZE)*100:.0f}%)')\n",
    "print(f'   - Test set: {len(X_test):,} samples ({TEST_SIZE*100:.0f}%)')\n",
    "print(f'   - Stratified by: quality score')\n",
    "\n",
    "print('\\n5. FEATURE SCALING')\n",
    "print(f'   - Method: StandardScaler')\n",
    "print(f'   - Training set: fit_transform()')\n",
    "print(f'   - Test set: transform()')\n",
    "\n",
    "print('\\n6. OUTPUT FILES')\n",
    "print(f'   - Location: {output_dir}/')\n",
    "print(f'   - Data files: 7 CSV files')\n",
    "print(f'   - Model artifacts: 4 PKL files')\n",
    "print(f'   - Visualizations: 9 PNG files')\n",
    "print(f'   - Summary: 1 JSON file')\n",
    "\n",
    "print('\\n' + '=' * 70)\n",
    "print('PREPROCESSING COMPLETED SUCCESSFULLY')\n",
    "print('Data is ready for model training')\n",
    "print('=' * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_checks = {\n",
    "    'No missing values in X_train': X_train_scaled.isnull().sum().sum() == 0,\n",
    "    'No missing values in X_test': X_test_scaled.isnull().sum().sum() == 0,\n",
    "    'Train-test dimensions match': X_train_scaled.shape[1] == X_test_scaled.shape[1],\n",
    "    'y_train matches X_train length': len(y_train) == len(X_train_scaled),\n",
    "    'y_test matches X_test length': len(y_test) == len(X_test_scaled),\n",
    "    'Feature scaling applied': abs(X_train_scaled.mean().mean()) < 0.01,\n",
    "    'All artifacts saved': all(os.path.exists(f'{output_dir}/{f}') \n",
    "                               for f in ['scaler.pkl', 'X_train.csv', 'y_train.csv'])\n",
    "}\n",
    "\n",
    "print('\\nFinal Verification Checks:')\n",
    "print('-' * 50)\n",
    "all_passed = True\n",
    "for check, passed in verification_checks.items():\n",
    "    status = 'PASS' if passed else 'FAIL'\n",
    "    symbol = '[OK]' if passed else '[X]'\n",
    "    print(f'  {symbol} {check}: {status}')\n",
    "    if not passed:\n",
    "        all_passed = False\n",
    "\n",
    "print('\\n' + '-' * 50)\n",
    "if all_passed:\n",
    "    print('All verification checks PASSED')\n",
    "else:\n",
    "    print('Some verification checks FAILED - please review')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}